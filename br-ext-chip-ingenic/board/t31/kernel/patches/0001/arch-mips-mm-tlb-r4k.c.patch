
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -27,7 +27,8 @@ extern void build_tlb_refill_handler(void);
  * Make sure all entries differ.  If they're not different
  * MIPS32 will take revenge ...
  */
-#define UNIQUE_ENTRYHI(idx) (CKSEG0 + ((idx) << (PAGE_SHIFT + 1)))
+#define UNIQUE_ENTRYHI(idx) (cpu_has_tlbinv ? ((CKSEG0 + ((idx) << (PAGE_SHIFT + 1))) | MIPS_EHINV) : \
+			     (CKSEG0 + ((idx) << (PAGE_SHIFT + 1))))
 
 /* Atomicity and interruptability */
 #ifdef CONFIG_MIPS_MT_SMTC
@@ -72,6 +73,7 @@ void local_flush_tlb_all(void)
 	unsigned long flags;
 	unsigned long old_ctx;
 	int entry;
+	int ftlbhighset;
 
 	ENTER_CRITICAL(flags);
 	/* Save old context and create impossible VPN2 value */
@@ -82,14 +84,29 @@ void local_flush_tlb_all(void)
 	entry = read_c0_wired();
 
 	/* Blast 'em all away. */
-	while (entry < current_cpu_data.tlbsize) {
-		/* Make sure all entries differ. */
-		write_c0_entryhi(UNIQUE_ENTRYHI(entry));
-		write_c0_index(entry);
-		mtc0_tlbw_hazard();
-		tlb_write_indexed();
-		entry++;
-	}
+	if (cpu_has_tlbinv) {
+		if (current_cpu_data.tlbsizevtlb) {
+			write_c0_index(0);
+			mtc0_tlbw_hazard();
+			tlbinvf();  /* invalide VTLB */
+		}
+		ftlbhighset = current_cpu_data.tlbsizevtlb + current_cpu_data.tlbsizeftlbsets;
+		for (entry=current_cpu_data.tlbsizevtlb;
+		     entry < ftlbhighset;
+		     entry++) {
+			write_c0_index(entry);
+			mtc0_tlbw_hazard();
+			tlbinvf();  /* invalide one FTLB set */
+		}
+	} else
+		while (entry < current_cpu_data.tlbsize) {
+			/* Make sure all entries differ. */
+			write_c0_entryhi(UNIQUE_ENTRYHI(entry));
+			write_c0_index(entry);
+			mtc0_tlbw_hazard();
+			tlb_write_indexed();
+			entry++;
+		}
 	tlbw_use_hazard();
 	write_c0_entryhi(old_ctx);
 	FLUSH_ITLB;
@@ -127,7 +144,8 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 		start = round_down(start, PAGE_SIZE << 1);
 		end = round_up(end, PAGE_SIZE << 1);
 		size = (end - start) >> (PAGE_SHIFT + 1);
-		if (size <= current_cpu_data.tlbsize/2) {
+		if ((current_cpu_data.tlbsizeftlbsets && (size <= current_cpu_data.tlbsize/8)) ||
+		    ((!current_cpu_data.tlbsizeftlbsets) && (size <= current_cpu_data.tlbsize/2))) {
 			int oldpid = read_c0_entryhi();
 			int newpid = cpu_asid(cpu, mm);
 
@@ -166,7 +184,8 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 	ENTER_CRITICAL(flags);
 	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 	size = (size + 1) >> 1;
-	if (size <= current_cpu_data.tlbsize / 2) {
+	if ((current_cpu_data.tlbsizeftlbsets && (size <= current_cpu_data.tlbsize/8)) ||
+	    ((!current_cpu_data.tlbsizeftlbsets) && (size <= current_cpu_data.tlbsize/2))) {
 		int pid = read_c0_entryhi();
 
 		start &= (PAGE_MASK << 1);
